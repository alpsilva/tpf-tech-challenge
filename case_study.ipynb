{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para esse caso de estudo, discutirei uma possível solução para o problema apresentado.\n",
    "\n",
    "Alguns pontos observados inicialmente, ao olhar para o formato de dado usado como exemplo:\n",
    "\n",
    "- O relatório/fonte de dados está armazenado no que assumo ser uma planilha de Excel/google sheets. Isso é um ponto positivo, pois a maior parte das ferramentas de importação de dados tem uma integração razoável com esse tipo de arquivo.\n",
    "- Considero a fonte de dados como tendo uma certa estrutura, mesmo que o formato não seja o mais ideal para análises de dados.\n",
    "- Temos alguns dados \"soltos\", que são relevantes àquela coleta de dados, mas não se encaixam em nenhuma tabela. Isso indica que precisaremos de uma classe de dados mais complexa, algo que armazene todos os detalhes presentes na metade superior do relatório, além das tabelas presentes na metade inferior.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dadas essas observações, já é possível traçejar e implementar uma possível solução para o manuseio dos dados.\n",
    "\n",
    "Antes disso, porém, gostaria de destacar alguns pontos que irei \"assumir\" para esse estudo de caso, em nome da objetividade e clareza da solução.\n",
    "\n",
    "- Suposição 1: Todos as células presentes no relatório são fixas, isso é, entre um relatório e outro, não ocorrerá de uma descrição de dado e seu valor atrelado mudarem de lugar numa frequência que necessite de retrabalho constante.\n",
    "- Suposição 2: Todos os relatórios são iguais. Além das células não mudarem de lugar, todos os relatórios possuirão as mesmas células e os mesmos tipos de dados contidos nelas. Dessa forma, é possível implementar uma solução genérica que funcione em qualquer relatório enviado.\n",
    "- Suposição 3: Não é necessário separar as tabelas de movimentos/contagem de veículos. Pude notar por meio da análise prévia do relatório que existe uma separação entre os períodos de coleta (manhã, tarde e noite) e até entre os intervalos do mesmo período. O dado do intervalo em si é, claro, muito importante, mas é possível armazenar todos os períodos e intervalos em apenas uma estrutura de dados, sem impactar a capacidade de fazermos consultas a períodos e intervalos específicos. Para ser franco, é possível que tenha um impacto negativo na performance, pois teríamos tabelas maiores, mas é um custo ínfimo se comparado a praticidade e facilidade de implementação ao trabalharmos com apenas uma tabela.\n",
    "- Suposição 4: Cada conjunto de colunas [Horário] + [Auto, Bus, Cam., Moto, Bici. UVP] corresponde a apenas 1 movimento. Para estruturação no formato de tabela, faremos com que o movimento seja mais uma coluna."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após todas as observações e suposições detalhadas, podemos seguir adiante com os detalhes da solução:\n",
    "\n",
    "1. O coração da solução serão os objetos do tipo dataframe, muito utilizados para representar dados colunares.\n",
    "2. Comumente, a biblioteca de python \"Pandas\" é utilizada para manuseio de dataframes, mas para esse exercício, utilizarei a biblioteca \"Polars\" que é mais nova (e por isso menos \"estável\" e atestada, porém tem performance muito superior se comparada à \"Pandas\". Fonte: https://h2oai.github.io/db-benchmark/). Além disso, para importação direta de datas, será necessário plugar a lib \"pyarrow\" ao \"Polars\".\n",
    "3. Como citado na etapa de observação, temos alguns dados que não cabem na visão de dataframe construída até aqui, como \"Ponto de Pesquisa\" ou \"Endereço\". É possível incorporar \"data da pesquisa\" na tabela, se for necessário, mas nesse ponto, não está clara a necessidade disso. Sendo assim, faz-se necessário uma classe que armazene os dados gerais e dataframe. Essa abordagem talvez não faça sentido num Python Notebook como esse, mas tem suas vantagens quando aplicada à produção de um projeto.\n",
    "4. Será necessário um script que extraia todos os dados relevantes da planilha e os use para compor os objetos estruturados criados em Python. Para esse fim, a biblioteca \"openpyxl\" será usada. Ela permite que cada célula individual de um arquivo .xlsx seja acessada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para começar, instalamos e importamos as dependências necessárias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: polars in /home/alps2/.local/lib/python3.10/site-packages (0.14.11)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: openpyxl in /home/alps2/.local/lib/python3.10/site-packages (3.0.10)\n",
      "Requirement already satisfied: et-xmlfile in /home/alps2/.local/lib/python3.10/site-packages (from openpyxl) (1.1.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pyarrow in /home/alps2/.local/lib/python3.10/site-packages (9.0.0)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /home/alps2/.local/lib/python3.10/site-packages (from pyarrow) (1.23.2)\n"
     ]
    }
   ],
   "source": [
    "# These extra bits are fail-safes to ensure the packages are being installed in\n",
    "# the jupyter kernel that is actually, currently, running\n",
    "\n",
    "import sys\n",
    "!{sys.executable} -m pip install polars\n",
    "!{sys.executable} -m pip install openpyxl\n",
    "!{sys.executable} -m pip install pyarrow\n",
    "\n",
    "import polars as pl\n",
    "import openpyxl\n",
    "from datetime import datetime, time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementação do scrip extrator de dados.\n",
    "\n",
    "De forma geral, o extrator funciona acessando células pré-determinadas onde se encontram as informações gerais,\n",
    "mas extrai informações de tabela para criação do DF (DataFrame) de forma mais dinâmica. Vale destacar a separação de intervalos de tempo em 2 colunas, interval_start e interval_end, ambas já processadas com o tipo datetime.Time (ou pl.Time, caso no DF) para maior facilidade de consultas, e também o fato de que o dado para \"Movimento\" foi transferido para uma coluna.\n",
    "\n",
    "Na planilha passada como exemplo, notei que a cada bloco de intervalos era possível encontrar um valor entre um segmento de tabela e outro, na coluna UVP. Imediatamente imaginei que seria a somo dos UVP's acima, mas percebi que a conta nem sempre batia, mas sempre por pouco (1 pra mais ou pra menos). Sendo assim, assumi que era uma flutuação decorrente de algum arredondamento com operações em números decimais que não estava visível no exemplo, e decidi não registrar esse dado, sendo que sempre é possível somar os UVP's de um bloco de coletas para termos o dado novamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xlsx_extractor(file_path: str):\n",
    "    \"\"\"\n",
    "    Receives a .xlsx file path.\n",
    "    return the data extracted from the sheet.    \n",
    "    \"\"\"\n",
    "    def extract_hour_from_interval(date_interval: str):\n",
    "        \"\"\"\n",
    "        Receives a string in the format:\n",
    "        \"hh:mm às hh:mm\"\n",
    "        Returns the 2 hours in datetime.time format.\n",
    "        \"\"\"\n",
    "        start_time = date_interval[:5]\n",
    "        end_time = date_interval[9:]\n",
    "\n",
    "        start_time = datetime.strptime(start_time, '%H:%M').time()\n",
    "        end_time = datetime.strptime(end_time, '%H:%M').time()\n",
    "\n",
    "        return start_time, end_time\n",
    "\n",
    "    workbook = openpyxl.load_workbook(file_path)\n",
    "    sheet = workbook.active\n",
    "\n",
    "    # Getting general data\n",
    "\n",
    "    research_point = sheet['B2'].value\n",
    "    address = sheet['B3'].value\n",
    "    research_date = sheet['B6'].value\n",
    "    researh_date_weekday = sheet['C6'].value\n",
    "    period_rows = [5, 8, 13]\n",
    "\n",
    "    intervals_fhp = {}\n",
    "    for period_row in period_rows:\n",
    "        period = sheet.cell(row=period_row, column=1).value\n",
    "        period = period[9:]\n",
    "\n",
    "        row_range = 1\n",
    "        if period == \"Tarde\":\n",
    "            row_range = 3\n",
    "\n",
    "        for i in range(row_range):\n",
    "            index = i + 1\n",
    "            interval = sheet.cell(row=period_row+index, column=5)\n",
    "            interval_start, interval_end = extract_hour_from_interval(interval.value)\n",
    "            fhp = sheet.cell(row=period_row+index, column=7).value\n",
    "            key = (period, interval_start, interval_end)\n",
    "            intervals_fhp[key] = fhp\n",
    "\n",
    "    # Getting table data\n",
    "\n",
    "    table_data = {\n",
    "        \"interval_start\": [],\n",
    "        \"interval_end\": [],\n",
    "        \"movimento\": [],\n",
    "        \"Auto\": [],\n",
    "        \"Bus\": [],\n",
    "        \"Cam.\": [],\n",
    "        \"Moto\": [],\n",
    "        \"Bici.\": [],\n",
    "        \"UVP\": [],\n",
    "    }\n",
    "\n",
    "    # Iterate through rows and movimentos to get count data.\n",
    "\n",
    "    movimentos_columns = [2, 8]\n",
    "\n",
    "    for movimento_column in movimentos_columns:\n",
    "        movimento = sheet.cell(row=16, column=movimento_column).value\n",
    "\n",
    "        # getting interval separately\n",
    "        for row in sheet.iter_rows(min_row=19, min_col=1, max_row=22, max_col=1, values_only=True):\n",
    "            interval = row[0]\n",
    "            interval_start, interval_end = extract_hour_from_interval(interval)\n",
    "            table_data[\"interval_start\"].append(interval_start)\n",
    "            table_data[\"interval_end\"].append(interval_end)\n",
    "\n",
    "        min_col = movimento_column\n",
    "        max_col = min_col+5\n",
    "\n",
    "        for row in sheet.iter_rows(min_row=19, min_col=min_col, max_row=22, max_col=max_col, values_only=True):\n",
    "            table_data[\"movimento\"].append(int(movimento))\n",
    "            table_data[\"Auto\"].append(int(row[0]))\n",
    "            table_data[\"Bus\"].append(int(row[1]))\n",
    "            table_data[\"Cam.\"].append(int(row[2]))\n",
    "            table_data[\"Moto\"].append(int(row[3]))\n",
    "            table_data[\"Bici.\"].append(int(row[4]))\n",
    "            table_data[\"UVP\"].append(int(row[5]))\n",
    "\n",
    "    columns = [\n",
    "        (\"interval_start\", pl.Time),\n",
    "        (\"interval_end\", pl.Time),\n",
    "        (\"movimento\", pl.Int64),\n",
    "        (\"Auto\", pl.Int64),\n",
    "        (\"Bus\", pl.Int64),\n",
    "        (\"Cam.\", pl.Int64),\n",
    "        (\"Moto\", pl.Int64),\n",
    "        (\"Bici.\", pl.Int64),\n",
    "        (\"UVP\", pl.Float64),\n",
    "    ]\n",
    "    dataframe = pl.DataFrame(table_data, columns=columns)\n",
    "\n",
    "    return {\n",
    "        \"research_point\": research_point,\n",
    "        \"address\": address,\n",
    "        \"research_date\": research_date,\n",
    "        \"researh_date_weekday\": researh_date_weekday,\n",
    "        \"intervals_fhp\": intervals_fhp,\n",
    "        \"dataframe\": dataframe\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testando extrator e visualizando o objeto dataframe criado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "research_point : 4.0\n",
      "address : Rua tal\n",
      "research_date : 2022-08-01 00:00:00\n",
      "researh_date_weekday : Segunda\n",
      "intervals_fhp : {('Manhã', datetime.time(7, 30), datetime.time(8, 30)): 0.87, ('Tarde', datetime.time(12, 0), datetime.time(13, 0)): 0.6, ('Tarde', datetime.time(14, 30), datetime.time(15, 30)): 0.67, ('Tarde', datetime.time(17, 0), datetime.time(18, 0)): 0.62, ('Noite', datetime.time(20, 0), datetime.time(21, 0)): 0.71}\n",
      "shape: (5, 9)\n",
      "┌────────────────┬──────────────┬───────────┬──────┬─────┬──────┬──────┬───────┬───────┐\n",
      "│ interval_start ┆ interval_end ┆ movimento ┆ Auto ┆ ... ┆ Cam. ┆ Moto ┆ Bici. ┆ UVP   │\n",
      "│ ---            ┆ ---          ┆ ---       ┆ ---  ┆     ┆ ---  ┆ ---  ┆ ---   ┆ ---   │\n",
      "│ time           ┆ time         ┆ i64       ┆ i64  ┆     ┆ i64  ┆ i64  ┆ i64   ┆ f64   │\n",
      "╞════════════════╪══════════════╪═══════════╪══════╪═════╪══════╪══════╪═══════╪═══════╡\n",
      "│ 07:30:00       ┆ 07:45:00     ┆ 1         ┆ 131  ┆ ... ┆ 1    ┆ 16   ┆ 1     ┆ 154.0 │\n",
      "├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌┤\n",
      "│ 07:45:00       ┆ 08:00:00     ┆ 1         ┆ 142  ┆ ... ┆ 0    ┆ 33   ┆ 0     ┆ 174.0 │\n",
      "├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌┤\n",
      "│ 08:00:00       ┆ 08:15:00     ┆ 1         ┆ 118  ┆ ... ┆ 0    ┆ 17   ┆ 2     ┆ 155.0 │\n",
      "├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌┤\n",
      "│ 08:15:00       ┆ 08:30:00     ┆ 1         ┆ 80   ┆ ... ┆ 2    ┆ 16   ┆ 0     ┆ 119.0 │\n",
      "├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌┤\n",
      "│ 07:30:00       ┆ 07:45:00     ┆ 2         ┆ 40   ┆ ... ┆ 1    ┆ 12   ┆ 0     ┆ 46.0  │\n",
      "└────────────────┴──────────────┴───────────┴──────┴─────┴──────┴──────┴───────┴───────┘\n"
     ]
    }
   ],
   "source": [
    "file_path = \"./case_study_assets/TPF-test.xlsx\"\n",
    "extracted_data = xlsx_extractor(file_path)\n",
    "for key in extracted_data:\n",
    "    if key != \"dataframe\":\n",
    "        print(key, \":\", extracted_data[key])\n",
    "\n",
    "df = extracted_data['dataframe']\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criação de uma classe que abstrai a extração e manuseio dos dados.\n",
    "\n",
    "Em produção, incluímos o extrator na classe.\n",
    "\n",
    "E também criamos algumas funções que abstraem consultas comuns que podem ser interessantes, como \"Busque todas as contagens para o movimento 1\", ou \"Busque todas as contagens que aconteceram durante esse intervalo de tempo\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VehicleCount:\n",
    "    def __init__(self, sheet_file_path: str):\n",
    "        \"\"\" Constructor \"\"\"\n",
    "        extracted_data = xlsx_extractor(sheet_file_path)\n",
    "        self.research_point = extracted_data['research_point']\n",
    "        self.address = extracted_data['address']\n",
    "        self.research_date = extracted_data['research_date']\n",
    "        self.researh_date_weekday = extracted_data['researh_date_weekday']\n",
    "        self.intervals_fhp = extracted_data['intervals_fhp']\n",
    "        self.dataframe = extracted_data['dataframe']\n",
    "    \n",
    "    def xlsx_extractor(file_path: str):\n",
    "        \"\"\"\n",
    "        Receives a .xlsx file path.\n",
    "        return the data extracted from the sheet.    \n",
    "        \"\"\"\n",
    "        def extract_hour_from_interval(date_interval: str):\n",
    "            \"\"\"\n",
    "            Receives a string in the format:\n",
    "            \"hh:mm às hh:mm\"\n",
    "            Returns the 2 hours in datetime.time format.\n",
    "            \"\"\"\n",
    "            start_time = date_interval[:5]\n",
    "            end_time = date_interval[9:]\n",
    "\n",
    "            start_time = datetime.strptime(start_time, '%H:%M').time()\n",
    "            end_time = datetime.strptime(end_time, '%H:%M').time()\n",
    "\n",
    "            return start_time, end_time\n",
    "\n",
    "        workbook = openpyxl.load_workbook(file_path)\n",
    "        sheet = workbook.active\n",
    "\n",
    "        # Getting general data\n",
    "\n",
    "        research_point = sheet['B2'].value\n",
    "        address = sheet['B3'].value\n",
    "        research_date = sheet['B6'].value\n",
    "        researh_date_weekday = sheet['C6'].value\n",
    "        period_rows = [5, 8, 13]\n",
    "\n",
    "        intervals_fhp = {}\n",
    "        for period_row in period_rows:\n",
    "            period = sheet.cell(row=period_row, column=1).value\n",
    "            period = period[9:]\n",
    "\n",
    "            row_range = 1\n",
    "            if period == \"Tarde\":\n",
    "                row_range = 3\n",
    "\n",
    "            for i in range(row_range):\n",
    "                index = i + 1\n",
    "                interval = sheet.cell(row=period_row+index, column=5)\n",
    "                interval_start, interval_end = extract_hour_from_interval(interval.value)\n",
    "                fhp = sheet.cell(row=period_row+index, column=7).value\n",
    "                key = (period, interval_start, interval_end)\n",
    "                intervals_fhp[key] = fhp\n",
    "\n",
    "        # Getting table data\n",
    "\n",
    "        table_data = {\n",
    "            \"interval_start\": [],\n",
    "            \"interval_end\": [],\n",
    "            \"movimento\": [],\n",
    "            \"Auto\": [],\n",
    "            \"Bus\": [],\n",
    "            \"Cam.\": [],\n",
    "            \"Moto\": [],\n",
    "            \"Bici.\": [],\n",
    "            \"UVP\": [],\n",
    "        }\n",
    "\n",
    "        # Iterate through rows and movimentos to get count data.\n",
    "\n",
    "        movimentos_columns = [2, 8]\n",
    "\n",
    "        for movimento_column in movimentos_columns:\n",
    "            movimento = sheet.cell(row=16, column=movimento_column).value\n",
    "\n",
    "            # getting interval separately\n",
    "            for row in sheet.iter_rows(min_row=19, min_col=1, max_row=22, max_col=1, values_only=True):\n",
    "                interval = row[0]\n",
    "                interval_start, interval_end = extract_hour_from_interval(interval)\n",
    "                table_data[\"interval_start\"].append(interval_start)\n",
    "                table_data[\"interval_end\"].append(interval_end)\n",
    "\n",
    "            min_col = movimento_column\n",
    "            max_col = min_col+5\n",
    "\n",
    "            for row in sheet.iter_rows(min_row=19, min_col=min_col, max_row=22, max_col=max_col, values_only=True):\n",
    "                table_data[\"movimento\"].append(int(movimento))\n",
    "                table_data[\"Auto\"].append(int(row[0]))\n",
    "                table_data[\"Bus\"].append(int(row[1]))\n",
    "                table_data[\"Cam.\"].append(int(row[2]))\n",
    "                table_data[\"Moto\"].append(int(row[3]))\n",
    "                table_data[\"Bici.\"].append(int(row[4]))\n",
    "                table_data[\"UVP\"].append(int(row[5]))\n",
    "\n",
    "        columns = [\n",
    "            (\"interval_start\", pl.Time),\n",
    "            (\"interval_end\", pl.Time),\n",
    "            (\"movimento\", pl.Int64),\n",
    "            (\"Auto\", pl.Int64),\n",
    "            (\"Bus\", pl.Int64),\n",
    "            (\"Cam.\", pl.Int64),\n",
    "            (\"Moto\", pl.Int64),\n",
    "            (\"Bici.\", pl.Int64),\n",
    "            (\"UVP\", pl.Float64),\n",
    "        ]\n",
    "        dataframe = pl.DataFrame(table_data, columns=columns)\n",
    "\n",
    "        return {\n",
    "            \"research_point\": research_point,\n",
    "            \"address\": address,\n",
    "            \"research_date\": research_date,\n",
    "            \"researh_date_weekday\": researh_date_weekday,\n",
    "            \"intervals_fhp\": intervals_fhp,\n",
    "            \"dataframe\": dataframe\n",
    "        }\n",
    "\n",
    "    def get_counts_in_movimento(self, movimento: int):\n",
    "        \"\"\"\n",
    "        Receives an int that represents the movimento number.\n",
    "        returns a sliced dataframe with only records that belong to the movimento.\n",
    "        \"\"\"\n",
    "        filtered_df = self.dataframe.filter(pl.col(\"movimento\") == movimento)\n",
    "        return filtered_df\n",
    "\n",
    "    def get_counts_in_interval(self, start_time: str, end_time: str):\n",
    "        \"\"\"\n",
    "        Receives start and end times that represent the interval.\n",
    "        returns a sliced dataframe with only records that belong to the interval.\n",
    "        \"\"\"\n",
    "        date_format = '%H:%M'\n",
    "        start_time = pl.lit(start_time).str.strptime(pl.Time, fmt=date_format)\n",
    "        end_time = pl.lit(end_time).str.strptime(pl.Time, fmt=date_format)\n",
    "        filtered_df = self.dataframe.filter(\n",
    "            (pl.col(\"interval_start\") >= start_time) & (pl.col(\"interval_end\") <= end_time)\n",
    "        )\n",
    "        return filtered_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc = VehicleCount(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ponto de Pesquisa: 4.0\n",
      "Endereço: Rua tal\n"
     ]
    }
   ],
   "source": [
    "print(\"Ponto de Pesquisa:\", vc.research_point)\n",
    "print(\"Endereço:\", vc.address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contagens do movimento 1:\n",
      "shape: (4, 9)\n",
      "┌────────────────┬──────────────┬───────────┬──────┬─────┬──────┬──────┬───────┬───────┐\n",
      "│ interval_start ┆ interval_end ┆ movimento ┆ Auto ┆ ... ┆ Cam. ┆ Moto ┆ Bici. ┆ UVP   │\n",
      "│ ---            ┆ ---          ┆ ---       ┆ ---  ┆     ┆ ---  ┆ ---  ┆ ---   ┆ ---   │\n",
      "│ time           ┆ time         ┆ i64       ┆ i64  ┆     ┆ i64  ┆ i64  ┆ i64   ┆ f64   │\n",
      "╞════════════════╪══════════════╪═══════════╪══════╪═════╪══════╪══════╪═══════╪═══════╡\n",
      "│ 07:30:00       ┆ 07:45:00     ┆ 1         ┆ 131  ┆ ... ┆ 1    ┆ 16   ┆ 1     ┆ 154.0 │\n",
      "├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌┤\n",
      "│ 07:45:00       ┆ 08:00:00     ┆ 1         ┆ 142  ┆ ... ┆ 0    ┆ 33   ┆ 0     ┆ 174.0 │\n",
      "├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌┤\n",
      "│ 08:00:00       ┆ 08:15:00     ┆ 1         ┆ 118  ┆ ... ┆ 0    ┆ 17   ┆ 2     ┆ 155.0 │\n",
      "├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌┤\n",
      "│ 08:15:00       ┆ 08:30:00     ┆ 1         ┆ 80   ┆ ... ┆ 2    ┆ 16   ┆ 0     ┆ 119.0 │\n",
      "└────────────────┴──────────────┴───────────┴──────┴─────┴──────┴──────┴───────┴───────┘\n",
      "Soma dos UVP's do movimento 1: 602.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Contagens do movimento 1:\")\n",
    "filtered_df = vc.get_counts_in_movimento(1)\n",
    "print(filtered_df)\n",
    "\n",
    "uvp_sum = pl.sum(filtered_df.get_column(\"UVP\"))\n",
    "print(\"Soma dos UVP's do movimento 1:\", uvp_sum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contagens entre o intervalo 07:45 às 08:15\n",
      "shape: (4, 9)\n",
      "┌────────────────┬──────────────┬───────────┬──────┬─────┬──────┬──────┬───────┬───────┐\n",
      "│ interval_start ┆ interval_end ┆ movimento ┆ Auto ┆ ... ┆ Cam. ┆ Moto ┆ Bici. ┆ UVP   │\n",
      "│ ---            ┆ ---          ┆ ---       ┆ ---  ┆     ┆ ---  ┆ ---  ┆ ---   ┆ ---   │\n",
      "│ time           ┆ time         ┆ i64       ┆ i64  ┆     ┆ i64  ┆ i64  ┆ i64   ┆ f64   │\n",
      "╞════════════════╪══════════════╪═══════════╪══════╪═════╪══════╪══════╪═══════╪═══════╡\n",
      "│ 07:45:00       ┆ 08:00:00     ┆ 1         ┆ 142  ┆ ... ┆ 0    ┆ 33   ┆ 0     ┆ 174.0 │\n",
      "├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌┤\n",
      "│ 08:00:00       ┆ 08:15:00     ┆ 1         ┆ 118  ┆ ... ┆ 0    ┆ 17   ┆ 2     ┆ 155.0 │\n",
      "├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌┤\n",
      "│ 07:45:00       ┆ 08:00:00     ┆ 2         ┆ 47   ┆ ... ┆ 0    ┆ 8    ┆ 0     ┆ 49.0  │\n",
      "├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌┤\n",
      "│ 08:00:00       ┆ 08:15:00     ┆ 2         ┆ 40   ┆ ... ┆ 0    ┆ 10   ┆ 0     ┆ 43.0  │\n",
      "└────────────────┴──────────────┴───────────┴──────┴─────┴──────┴──────┴───────┴───────┘\n"
     ]
    }
   ],
   "source": [
    "start_time = \"07:45\"\n",
    "end_time = \"08:15\"\n",
    "print(f\"Contagens entre o intervalo {start_time} às {end_time}\")\n",
    "filtered_df = vc.get_counts_in_interval(start_time, end_time)\n",
    "print(filtered_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
